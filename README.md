# IntDT: A Large-scale Roadside Dual-Lidar Dataset

This project contains the official implementation of the IntDT dataset—a large-scale roadside dual-LiDAR dataset proposed in the paper.
[IntDT: A comprehensive roadside dual-lidar dataset and benchmarks for urban intersection digital twins](https://pdf.sciencedirectassets.com/272637/1-s2.0-S1569843224X20166/1-s2.0-S1569843225006272/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEEgaCXVzLWVhc3QtMSJGMEQCICDUL8a1tmZYXcLrhkPq5MHElWWyv3IOJzMqsMQIbDT2AiAY8ptmTJ2AJM52Mzx9uvwYOkfk1Id%2BVxMcmwpsX5KhBCqzBQgQEAUaDDA1OTAwMzU0Njg2NSIMEGJ0JlLSsXYU%2ByldKpAFBuwLFf221HFlrv8L7%2BFFAxyRsbgNt6lUsasa%2FNXruiHALA1Yr5gHn2%2BDiZBZfPnZrZ%2Bi%2BxOEc8X%2BYGuyNGRMyAE3dAF4rTO5WzQs%2FFk07cS8n%2FxAUsV0B1O3UMtgMsQCXUzjfNHVQgT%2FkP%2FaN7Ces412Fsj24xOqmSwRYFPBIMz1HhTU6a%2FIc2daYr8PadtH2yfdBVrQ3UlHaxjzvKMk7biw7LxEolscB7d3mdZr4EqPooyy4fNVXlM3uuax9CG7N%2BHmF11VnZOK5TMyB78AsPZp%2FBJxpME4hiJM0ttgSZuiDxWNVHSn1CG1COgqf%2FlHtOwfk5keprg2CbkWE%2FAO9Y9Gp1KgbOB7n0QcI0wyMp77GU13PIVPpjZ%2BZLufQEa6%2FkA73AJCczSmiKPI4VCFSK20BiEOgJbEwwpKlFesyoWvEnw0a%2FFX1UqUVm3Y3QdBX0MYqBshB1Zpj03GXWcqa%2BBypKRaH%2BBnsANLVOOW0KxzF%2BpC7Y1ZKrLHoRgonWuwkie8jtl3dpom%2BziC2pQGkvISK7KttR1i1BM4YTbFCDM8f8SCk1ReVzhkjOhnLNxWNoWBCy9PPXOrK4rWIYkdgub6bCV1kMG7n0kc%2F75dAuu8c96r%2FABRVvbBbh%2B5xEgH1h%2BBx2R9jJSuH7BsUhjhLejaPFiYXPELKppfsPs%2FOCPdQ4q3f2swuYOMqkGRcj7fhAFlQ7ZOM99%2Fst%2FLVCPxs1mRd1ooAQjrX0cvi3WnnC6aqcONJp%2FUA%2B7tqF2i1K3XUNEImhvK%2B5VPkIpyllJt02kGKpGYuGnBSOEs9rvWMu%2FROIl9gg1XYtPqc5dWGIM2DsGlxEvrxf369mOenm3YuB5TrCNE69lKtVwHlMGb0fswjqS6yQY6sgFqYE2ZDmhwiXrNuOznPOrgrR5vlCyZ6OzpQtKF0Nyprr6MW9X4kIpXxnSIMtXtr6KPWqOb07uIWoSxFUhLKtE03knCrSoUAiIuzvTA3rfXG2%2Fl0LaLTHPs%2BotoHMAVD52XGGUQB%2FJ9A4pKodqSZaRYBzjfJqG4rsg4nK9pOdGi0drMfCAz%2BwZJFOjdgBc%2BVqJMdnCv%2BA9XqGd0cN%2FaJYucvLY6TwrdZG2UDs%2Fqv0Twh27t&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251202T074637Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYQHUIJ4KV%2F20251202%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=8dcef5a9b1c0fda1b1f0f86c9d3078b5b20927c8e2da87c3dbb19ae144e91322&hash=46c4806e7fae98c2d7d3fea871a00e7d6961c8c211bd0625a5d05f927d290d98&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1569843225006272&tid=spdf-1d874d96-03ea-4f16-a29c-e13a0b12396a&sid=8b254d133a437240bd7bdd375e021ef2c038gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0a0e5804555f525157&rr=9a7936275c06b445&cc=hk&kca=eyJrZXkiOiJkSHZjV2k4a0UyLzRGRFFPZFByNTB0cXl1WHFDOVRUWG1lZTZtb0M2THJ6dHpySUlHclRydkp2b01mcDErYkhVenNIdHk1Rk9mRXlId1ExTmVvb3FLYTFubGlobysweVVHT1luN0p2V29ENGlBMVBMMlFwRGdZaXZ1cVZuTXIxQnlYTXFpY0svV0t2bUlwMjRyWTA1YW0zU0hxb1d0bUQwTkk4bzFLT3NXc05mUE9vPSIsIml2IjoiZWFiNTQxNzg0MDkzYmJiMTMwMTA5MjYwYWE2M2E1Y2IifQ==_1764661614539)

Wen Xiao, Dianyu Yu, Miao Tang, Shichen Zhang, Pu Zhao, Peiguang Li, Chengwen Song, Jiaxing Zhang, Nengcheng Chen

[DOI:doi.org/10.1016/j.jag.2025.104980](doi.org/10.1016/j.jag.2025.104980)

## Overview
- [Data Download](#Data-Download)
- [Benchmark](#Benchmark)
  - [3D Object Detection](#3D-Object-Detection)
  - [Semi-supervised 3D object detection](#Semi-supervised-3D-object-detection)
  - [3D Object Tracking](#3D-Object-Tracking)
  - [Moving object segmentation](#Moving-object-segmentation)
  - [Point cloud completion](#Point-cloud-completion)
- [Acknowledgment](#Acknowledgment)

## Data Download
Our dataset is freely available to researchers. Please download and sign our [agreement](https://docs.google.com/document/d/14ufBczTjLYnxm5bWkFROsz9FYEugZ2QL/edit?usp=sharing&ouid=110390481963822269546&rtpof=true&sd=true) and send it to the provided email address (wen.xiao@cug.edu.cn). You will receive the download link within one week.
After downloading the data, please put the data in the following structure:
```shell
├── IntDT-S-dataset
│   ├── 0011
|      |── label
|      |── lidar
|      |── metadata.json
│   ├── 0012
│   ├── 0021
│   ├── 0022
│   ├── ...
├── IntDT-D-dataset
│   ├── 001
|      |── Lidar1
|         |── label
|         |── lidar
|         |── metadata.json
|      |── Lidar2
|         |── label
|         |── lidar
|         |── metadata.json
|      |── metadata.json
│   ├── 002
│   ├── 003
│   ├── ...
```


## Benchmark

### 3D Object Detection

#### Results of detection models on the IntDT-D test set.
<table>
  <tr>
    <th rowspan="2">Method</th>
    <th colspan="4">Vehicle (AP@50)(%)</th>
    <th colspan="4">Pedestrian (AP@50)(%)</th>
    <th colspan="4">Cyclist (AP@50)(%)</th>
    <th rowspan="2">mAP(%)</th>
  </tr>
  <tr>
    <th></th>
    <th>Overall</th>
    <th>0–30 m</th>
    <th>30–50 m</th>
    <th>50–100 m</th>
    <th>Overall</th>
    <th>0–30 m</th>
    <th>30–50 m</th>
    <th>50–100 m</th>
    <th>Overall</th>
    <th>0–30 m</th>
    <th>30–50 m</th>
    <th>50–100 m</th>
    <th></th>
  </tr>
  <tr>
    <td>IA-SSD</td>
    <td>28.34</td>
    <td>78.22</td>
    <td>31.61</td>
    <td>14.67</td>
    <td>17.94</td>
    <td>24.53</td>
    <td>13.90</td>
    <td>11.66</td>
    <td>20.11</td>
    <td>31.30</td>
    <td>11.30</td>
    <td>13.33</td>
    <td>22.13</td>
  </tr>
  <tr>
    <td>PV-RCNN</td>
    <td>26.84</td>
    <td>75.64</td>
    <td>30.12</td>
    <td>13.40</td>
    <td>16.07</td>
    <td>32.38</td>
    <td>8.15</td>
    <td>10.94</td>
    <td>21.84</td>
    <td>50.89</td>
    <td>15.40</td>
    <td>2.91</td>
    <td>21.58</td>
  </tr>
  <tr>
    <td>CenterPoint</td>
    <td>22.05</td>
    <td>67.23</td>
    <td>21.58</td>
    <td>12.29</td>
    <td>27.84</td>
    <td>44.38</td>
    <td>13.91</td>
    <td>25.64</td>
    <td>14.45</td>
    <td>30.11</td>
    <td>14.34</td>
    <td>2.32</td>
    <td>21.45</td>
  </tr>
</table>

### Semi-supervised 3D object detection

#### Performance comparison across different semi-supervised learning methods on IntDT-S validation set.
<table>
  <tr>
    <th rowspan="2">Method</th>
    <th colspan="4">Vehicle (AP@50)(%)</th>
    <th colspan="4">Pedestrian (AP@50)(%)</th>
    <th colspan="4">Cyclist (AP@50)(%)</th>
    <th rowspan="2">mAP(%)</th>
  </tr>
  <tr>
    <th>overall</th>
    <th>0-30m</th>
    <th>30-50m</th>
    <th>50m-inf</th>
    <th>overall</th>
    <th>0-30m</th>
    <th>30-50m</th>
    <th>50m-inf</th>
    <th>overall</th>
    <th>0-30m</th>
    <th>30-50m</th>
    <th>50m-inf</th>
  </tr>
  <tr>
    <td colspan="14" align="center"><strong>1%</strong></td>
  </tr>
  <tr>
    <td>CoIn</td>
    <td>33.55</td>
    <td>66.25</td>
    <td>36.7</td>
    <td>15.22</td>
    <td>7.59</td>
    <td>11.24</td>
    <td>9.86</td>
    <td>2.93</td>
    <td>2.68</td>
    <td>5.19</td>
    <td>2.39</td>
    <td>0.38</td>
    <td>14.6</td>
  </tr>
  <tr>
    <td>HINTED</td>
    <td>45.57</td>
    <td>72.8</td>
    <td>49.78</td>
    <td>28.59</td>
    <td>18.57</td>
    <td>25.81</td>
    <td>21.66</td>
    <td>10.79</td>
    <td>13.18</td>
    <td>25.08</td>
    <td>12.79</td>
    <td>4.79</td>
    <td>25.77</td>
  </tr>
  <tr>
    <td colspan="14" align="center"><strong>10%</strong></td>
  </tr>
  <tr>
    <td>CoIn</td>
    <td>58.54</td>
    <td>81.67</td>
    <td>68.63</td>
    <td>42.94</td>
    <td>41.45</td>
    <td>62.99</td>
    <td>44.95</td>
    <td>20.27</td>
    <td>61.62</td>
    <td>87.53</td>
    <td>62.57</td>
    <td>31.84</td>
    <td>53.87</td>
  </tr>
  <tr>
    <td>HINTED</td>
    <td>60.97</td>
    <td>81.49</td>
    <td>66.36</td>
    <td>46.76</td>
    <td>45.24</td>
    <td>60.82</td>
    <td>49.79</td>
    <td>26.24</td>
    <td>70.21</td>
    <td>87.6</td>
    <td>72.05</td>
    <td>46.03</td>
    <td>58.81</td>
  </tr>
  <tr>
    <td colspan="14" align="center"><strong>20%</strong></td>
  </tr>
  <tr>
    <td>CoIn</td>
    <td>63.95</td>
    <td>84.68</td>
    <td>72.43</td>
    <td>48.92</td>
    <td>54.15</td>
    <td>74.3</td>
    <td>58.01</td>
    <td>32.81</td>
    <td>68.15</td>
    <td>92.39</td>
    <td>71.83</td>
    <td>40.67</td>
    <td>62.08</td>
  </tr>
  <tr>
    <td>HINTED</td>
    <td>66.12</td>
    <td>83.38</td>
    <td>74.16</td>
    <td>52.82</td>
    <td>55.64</td>
    <td>70.73</td>
    <td>60.85</td>
    <td>36.77</td>
    <td>73.94</td>
    <td>86.37</td>
    <td>76.17</td>
    <td>59.85</td>
    <td>65.23</td>
  </tr>
</table>

#### Performance comparison across different semi-supervised learning methods on IntDT-S test set.
<table>
  <tr>
    <th rowspan="2">Method</th>
    <th colspan="4">Vehicle (AP@50)(%)</th>
    <th colspan="4">Pedestrian (AP@50)(%)</th>
    <th colspan="4">Cyclist (AP@50)(%)</th>
    <th rowspan="2">mAP(%)</th>
  </tr>
  <tr>
    <th>overall</th>
    <th>0-30m</th>
    <th>30-50m</th>
    <th>50m-inf</th>
    <th>overall</th>
    <th>0-30m</th>
    <th>30-50m</th>
    <th>50m-inf</th>
    <th>overall</th>
    <th>0-30m</th>
    <th>30-50m</th>
    <th>50m-inf</th>
  </tr>
  <tr>
    <td colspan="14" align="center"><strong>1%</strong></td>
  </tr>
  <tr>
    <td>CoIn</td>
    <td>34.3</td>
    <td>65.69</td>
    <td>38.31</td>
    <td>15.5</td>
    <td>7.27</td>
    <td>11.01</td>
    <td>8.75</td>
    <td>2.91</td>
    <td>2.98</td>
    <td>5.25</td>
    <td>3.27</td>
    <td>0.57</td>
    <td>14.85</td>
  </tr>
  <tr>
    <td>HINTED</td>
    <td>45.5</td>
    <td>72.68</td>
    <td>51.8</td>
    <td>27.48</td>
    <td>18.6</td>
    <td>25.85</td>
    <td>21.32</td>
    <td>10.36</td>
    <td>14.15</td>
    <td>26</td>
    <td>12.5</td>
    <td>5.4</td>
    <td>26.08</td>
  </tr>
  <tr>
    <td colspan="14" align="center"><strong>10%</strong></td>
  </tr>
  <tr>
    <td>CoIn</td>
    <td>60.47</td>
    <td>82.06</td>
    <td>69.17</td>
    <td>42.63</td>
    <td>42.19</td>
    <td>63.93</td>
    <td>46.27</td>
    <td>19.4</td>
    <td>61.91</td>
    <td>86.37</td>
    <td>65.65</td>
    <td>31.78</td>
    <td>54.85</td>
  </tr>
  <tr>
    <td>HINTED</td>
    <td>62.50</td>
    <td>81.73</td>
    <td>68.36</td>
    <td>46.22</td>
    <td>44.01</td>
    <td>59.63</td>
    <td>48.23</td>
    <td>24.98</td>
    <td>69.62</td>
    <td>86.22</td>
    <td>74.17</td>
    <td>45.27</td>
    <td>58.71</td>
  </tr>
  <tr>
    <td colspan="14" align="center"><strong>20%</strong></td>
  </tr>
  <tr>
    <td>CoIn</td>
    <td>63.99</td>
    <td>84.73</td>
    <td>74.12</td>
    <td>49.06</td>
    <td>54.23</td>
    <td>75.88</td>
    <td>57.68</td>
    <td>31.87</td>
    <td>68.17</td>
    <td>91.89</td>
    <td>72.27</td>
    <td>41.33</td>
    <td>62.13</td>
  </tr>
  <tr>
    <td>HINTED</td>
    <td>67.46</td>
    <td>83.64</td>
    <td>74.11</td>
    <td>53.16</td>
    <td>55.72</td>
    <td>71.03</td>
    <td>59.26</td>
    <td>36.83</td>
    <td>74.01</td>
    <td>86.48</td>
    <td>77.23</td>
    <td>58.32</td>
    <td>65.73</td>
  </tr>
</table>


### 3D Object Tracking

#### Performance of object tracking baseline models evaluated on the IntDT-D test set.

<table>
    <tr>
        <th>Tracking</th>
        <th>Detection</th>
        <th>AMOTA (%)</th>
        <th>AMOTP (m)</th>
    </tr>
    <tr>
        <td rowspan="3">PC-TCNN</td>
        <td>IA-SSD</td>
        <td>65.6</td>
        <td>0.661</td>
    </tr>
    <tr>
        <td>PV-RCNN</td>
        <td>54.7</td>
        <td>0.714</td>
    </tr>
    <tr>
        <td>CenterPoint</td>
        <td>43.8</td>
        <td>0.797</td>
    </tr>
</table>

### Moving object segmentation
#### MOS results of moving object segmentation baseline models on the IntDT-S test set.
<table>
  <tr>
    <th rowspan="2">Method</th>
    <th colspan="2">IntDT-D</th>
  </tr>
  <tr>
    <th>IoU Moving</th>
    <th>IoU Static</th>
  </tr>
  <tr>
    <td>MotionSeg3D</td>
    <td>0.662</td>
    <td>0.977</td>
  </tr>
  <tr>
    <td>LMNet</td>
    <td>0.678</td>
    <td>0.979</td>
  </tr>
  <tr>
    <td>4DMOS</td>
    <td>0.669</td>
    <td>0.983</td>
  </tr>
</table>

#### MOS results of moving object segmentation baseline models on the IntDT-D test set.

<table>
  <tr>
    <th rowspan="2">Method</th>
    <th colspan="2">IntDT-D</th>
  </tr>
  <tr>
    <th>IoU Moving</th>
    <th>IoU Static</th>
  </tr>
  <tr>
    <td>MotionSeg3D</td>
    <td>0.660</td>
    <td>0.978</td>
  </tr>
  <tr>
    <td>LMNet</td>
    <td>0.382</td>
    <td>0.944</td>
  </tr>
  <tr>
    <td>4DMOS</td>
    <td>0.656</td>
    <td>0.981</td>
  </tr>
</table>

### Point cloud completion
#### The quantitative results of the two vehicle completion algorithms on the IntDT dataset.
<table>
  <tr>
    <th>Model</th>
    <th>CD-L1 (×10⁻³)</th>
    <th>CD-L2 (×10⁻³)</th>
    <th>F-score@1%</th>
  </tr>
  <tr>
    <td>Adapointr</td>
    <td>0.131</td>
    <td>0.027</td>
    <td>0.142</td>
  </tr>
  <tr>
    <td>ODGNet</td>
    <td>0.106</td>
    <td>0.019</td>
    <td>0.202</td>
  </tr>
</table>

## Acknowledgment
- [OpenPCDet](https://github.com/open-mmlab/OpenPCDet)
- [SUSTechPOINTS](https://github.com/naurril/SUSTechPOINTS)

Sincere appreciation for their great contributions.
